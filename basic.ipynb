{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T22:41:59.131870Z",
     "start_time": "2018-01-14T22:41:57.888152Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import importlib.util\n",
    "import scipy.misc\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "#Import the vizdoom package as \"vd\" since it can't be installed normally on Windows\n",
    "\n",
    "vizdoom = importlib.util.spec_from_file_location('vizdoom',\n",
    "                                                 'C:/Anaconda3/envs/doom/Lib/site-packages/vizdoom/vizdoom.pyd')\n",
    "vd = importlib.util.module_from_spec(vizdoom)\n",
    "vizdoom.loader.exec_module(vd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T22:41:59.159398Z",
     "start_time": "2018-01-14T22:41:59.132871Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Specify the game scenario and the screen format/resolution\n",
    "\n",
    "game = vd.DoomGame()\n",
    "game.set_screen_format(vd.ScreenFormat.BGR24)\n",
    "game.set_screen_resolution(vd.ScreenResolution.RES_160X120)\n",
    "game.load_config('basic.cfg')\n",
    "\n",
    "down_sample_ratio = 0.5\n",
    "width = int(game.get_screen_width()*down_sample_ratio)\n",
    "height = int(game.get_screen_height()*down_sample_ratio)\n",
    "channels = game.get_screen_channels()\n",
    "\n",
    "#Specify the available actions in the scenario\n",
    "\n",
    "shoot = [0, 0, 1]\n",
    "left = [1, 0, 0]\n",
    "right = [0, 1, 0]\n",
    "actions = [left, right, shoot]\n",
    "num_actions = len(actions)\n",
    "\n",
    "#Specify the Q-network learning parameters\n",
    "\n",
    "frame_delay = 12\n",
    "buffer_size = 10000\n",
    "epochs = 20\n",
    "steps_per_epoch = 2000\n",
    "discount_factor = 0.99\n",
    "learning_rate = 0.001\n",
    "start_epsilon = 1.0\n",
    "end_epsilon = 0.1\n",
    "batch_size = 100\n",
    "load_model = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T22:42:01.522190Z",
     "start_time": "2018-01-14T22:42:01.466636Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Create a buffer object that holds a set of training experiences (state-action-reward tuples)\n",
    "\n",
    "class Buffer():\n",
    "    def __init__(self, size=1000):\n",
    "        self.buffer = list()\n",
    "        self.length = len(self.buffer)\n",
    "        self.size = size\n",
    "        \n",
    "#Add new experiences to the buffer, removing old experiences to avoid exceeding the buffer size\n",
    "        \n",
    "    def add_experience(self, experiences):\n",
    "        if self.length + len(experiences) >= self.size:\n",
    "            self.buffer[0:(self.length + len(experiences)) - self.size] = []\n",
    "        \n",
    "        self.buffer.extend(experiences)\n",
    "        self.length = len(self.buffer)\n",
    "            \n",
    "#Return a batch of experience arrays randomly sampled from the buffer\n",
    "            \n",
    "    def sample_buffer(self, sample_size):\n",
    "        sample = np.random.randint(self.length, size=sample_size)\n",
    "        s1 = np.concatenate([self.buffer[idx][0] for idx in sample], axis=0)\n",
    "        a = np.array([self.buffer[idx][1] for idx in sample])\n",
    "        r = np.array([self.buffer[idx][2] for idx in sample])\n",
    "        s2 = np.concatenate([self.buffer[idx][3] for idx in sample], axis=0)\n",
    "        terminal = np.array([self.buffer[idx][4] for idx in sample], dtype=np.int32)\n",
    "        \n",
    "        return s1, a, r, s2, terminal\n",
    "\n",
    "#Downsample and normalize an image array representing the game state at a given time stamp\n",
    "\n",
    "def preprocess(image, down_sample_ratio=1):\n",
    "    if down_sample_ratio != 1:\n",
    "        image = scipy.misc.imresize(image, down_sample_ratio)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T22:42:05.427017Z",
     "start_time": "2018-01-14T22:42:05.011107Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Create a Q-network to estimate values and choose actions for a given state\n",
    "\n",
    "if load_model == False:\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    s_t = tf.placeholder(tf.float32, shape=[None, height, width, channels], name='state')\n",
    "    a_t = tf.placeholder(tf.int32, shape=[None], name='action')\n",
    "    Q_target = tf.placeholder(tf.float32, shape=[None, num_actions], name='Q_target')\n",
    "\n",
    "    input_layer = tf.reshape(s_t, [-1, height, width, channels], name='input_layer')\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer,\n",
    "                                 filters=32,\n",
    "                                 kernel_size=[8, 8],\n",
    "                                 strides=[4, 4],\n",
    "                                 padding='valid',\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name='conv1_layer')\n",
    "    conv2 = tf.layers.conv2d(inputs=conv1,\n",
    "                                 filters=64,\n",
    "                                 kernel_size=[4, 4],\n",
    "                                 strides=[2, 2],\n",
    "                                 padding='valid',\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name='conv2_layer')\n",
    "    flatten = tf.reshape(conv2, [-1, 6*8*64], name='flatten')\n",
    "    dense1 = tf.layers.dense(inputs=flatten,\n",
    "                                 units=512,\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name='dense1_layer')\n",
    "    Q_values = tf.layers.dense(inputs=dense1,\n",
    "                                   units=len(actions),\n",
    "                                   activation=None,\n",
    "                                   name='output_layer')        \n",
    "    \n",
    "best_action = tf.argmax(Q_values, 1)\n",
    "loss = tf.losses.mean_squared_error(Q_values, Q_target)\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate, name='adam').minimize(loss)\n",
    "\n",
    "def calculate_loss(session, s, q):\n",
    "    L, _ = session.run([loss, adam], feed_dict={s_t: s, Q_target: q})\n",
    "    \n",
    "    return L\n",
    "\n",
    "#Return the array of Q-values and the best action associated with a given state\n",
    "\n",
    "def get_Q_values(session, s):\n",
    "    Q = session.run(Q_values, feed_dict={s_t: s})\n",
    "\n",
    "    return Q\n",
    "    \n",
    "def choose_action(session, s):\n",
    "    a = session.run(best_action, feed_dict={s_t: s})\n",
    "    \n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:11:13.174660Z",
     "start_time": "2018-01-14T22:42:14.523571Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Mean Reward: -126.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Mean Reward: -125.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Mean Reward: -130.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Mean Reward: -128.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Mean Reward: -113.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Mean Reward: -65.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Mean Reward: -34.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Mean Reward: -16.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Mean Reward: -1.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Mean Reward: 19.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Mean Reward: 32.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Mean Reward: 45.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Mean Reward: 56.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Mean Reward: 64.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Mean Reward: 71.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Mean Reward: 76.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Mean Reward: 79.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Mean Reward: 81.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Mean Reward: 82.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Mean Reward: 82.425\n",
      "292440 time steps experienced during training\n",
      "10000 time steps in the buffer\n"
     ]
    }
   ],
   "source": [
    "#For each time step, collect the following data:\n",
    "#The current game state\n",
    "#The action that was taken taken\n",
    "#The reward obtained from the chosen action\n",
    "#The next game state (if the episode hasn't ended yet)\n",
    "#A variable indicating whether the episode is over yet\n",
    "\n",
    "\n",
    "exp_buffer = Buffer(size=buffer_size)\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "game.set_window_visible(True)\n",
    "game.init()\n",
    "t = 0\n",
    "\n",
    "#Accumulate experiences in the buffer using an epsilon-greedy strategy with three training phases\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_rewards = list()\n",
    "    \n",
    "    for step in trange(steps_per_epoch, leave=False):\n",
    "        experience = list()\n",
    "        game.new_episode()\n",
    "        \n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state()\n",
    "            state1 = preprocess(state.screen_buffer, down_sample_ratio)\n",
    "            \n",
    "#Explore the environment by choosing random actions with 100% probability for the first phase of training\n",
    "\n",
    "            if epoch < 0.2*epochs:\n",
    "                action = np.random.randint(num_actions)\n",
    "            \n",
    "#Increase the probability of greedily choosing an action by a constant amount at each epoch in the second phase\n",
    "            \n",
    "            elif epoch < 0.9*epochs:\n",
    "                epsilon = start_epsilon - (epoch + 1 - 0.2*epochs)*(start_epsilon-end_epsilon)/(0.7*epochs)\n",
    "            \n",
    "                if np.random.uniform(0, 1) <= epsilon:\n",
    "                    action = np.random.randint(num_actions)\n",
    "                \n",
    "                else:\n",
    "                    action = choose_action(session, state1)[0]\n",
    "\n",
    "#Select a random action with 10% probability in the final phase of training\n",
    "                \n",
    "            else:\n",
    "                if np.random.uniform(0, 1) <= end_epsilon:\n",
    "                    action = np.random.randint(num_actions)\n",
    "                    \n",
    "                else:\n",
    "                    action = choose_action(session, state1)[0]\n",
    "\n",
    "            reward = game.make_action(actions[action], frame_delay)\n",
    "            done = game.is_episode_finished()\n",
    "\n",
    "            if done == False:\n",
    "                state = game.get_state()\n",
    "                state2 = preprocess(state.screen_buffer, down_sample_ratio)\n",
    "        \n",
    "            elif done == True:\n",
    "                state2 = state1\n",
    "        \n",
    "            experience.append((state1, action, reward, state2, done))\n",
    "            t += 1\n",
    "            #time.sleep(0.02)\n",
    "        \n",
    "#Collect a list of experiences obtained from each new episode and add it to the buffer\n",
    "        \n",
    "            exp_buffer.add_experience(experience)\n",
    "        \n",
    "#Sample a minibatch from the buffer if there are enough experiences in the buffer\n",
    "\n",
    "        if exp_buffer.length > batch_size:\n",
    "            s1, a, r, s2, terminal = exp_buffer.sample_buffer(batch_size)\n",
    "            \n",
    "#Train the Q-network by using the minibatch to update the action-value function Q\n",
    "            \n",
    "            Q2 = np.max(get_Q_values(session, s2), axis=1)\n",
    "            target_Q = get_Q_values(session, s1)\n",
    "            target_Q[np.arange(batch_size), a] = r + discount_factor*(1 - terminal)*Q2\n",
    "            calculate_loss(session, s1, target_Q)\n",
    "            \n",
    "        epoch_rewards.append(game.get_total_reward())\n",
    "        #print('Episode Reward:', game.get_total_reward())\n",
    "        #print('Current Time Step:', t)\n",
    "        #time.sleep(2)\n",
    "        \n",
    "    print('Epoch {} Mean Reward: {}'.format(epoch + 1, np.mean(epoch_rewards)))\n",
    "        \n",
    "print('{} time steps experienced during training'.format(t))\n",
    "print('{} time steps in the buffer'.format(len(exp_buffer.buffer)))\n",
    "\n",
    "game.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T07:14:57.044422Z",
     "start_time": "2018-01-14T07:14:57.041419Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09078904,  0.08835138,  0.09053434,  0.09185897], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.new_episode()\n",
    "while not game.is_episode_finished():\n",
    "    state = game.get_state()\n",
    "    state1 = preprocess(state.screen_buffer, down_sample_ratio)\n",
    "    action = choose_action(session, state1)[0]\n",
    "    game.make_action(actions[action], frame_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T07:13:41.041046Z",
     "start_time": "2018-01-14T07:13:41.021027Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05094901  0.09078904  0.04323275]\n",
      " [-0.04370601  0.08835138  0.05150517]\n",
      " [-0.05217212  0.09053434  0.04699321]\n",
      " [-0.04630006  0.09185897  0.04737985]]\n",
      "[1 1 1 1]\n",
      "[-1. -1. -1. -1.]\n",
      "[[-0.05139191  0.09106207  0.04406736]\n",
      " [-0.04355836  0.08825099  0.05155002]\n",
      " [-0.05189302  0.09180053  0.04640573]\n",
      " [-0.04665237  0.09184078  0.04646797]]\n",
      "[ 0.09106207  0.08825099  0.09180053  0.09184078]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "sample = exp_buffer.sample_buffer(4)\n",
    "target_Q = get_Q_values(session, sample[0])\n",
    "a = choose_action(session, sample[0])\n",
    "r = sample[2]\n",
    "Q2 = np.max(get_Q_values(session, sample[3]), axis=1)\n",
    "print(target_Q)\n",
    "print(a)\n",
    "print(r)\n",
    "print(get_Q_values(session, sample[3]))\n",
    "print(Q2)\n",
    "print(sample[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T07:15:50.370339Z",
     "start_time": "2018-01-14T07:15:50.365335Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90984855 -0.91263152 -0.90911748 -0.90907763]\n",
      "[[-0.05094901 -0.90984857  0.04323275]\n",
      " [-0.04370601 -0.91263151  0.05150517]\n",
      " [-0.05217212 -0.90911746  0.04699321]\n",
      " [-0.04630006 -0.90907764  0.04737985]]\n"
     ]
    }
   ],
   "source": [
    "print(r + discount_factor*(1 - sample[4])*Q2)\n",
    "target_Q[np.arange(4), a] = r + discount_factor*(1 - sample[4])*Q2\n",
    "print(target_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T06:41:15.996415Z",
     "start_time": "2018-01-14T06:41:15.987406Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.527867e-05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(session, exp_buffer.sample_buffer(4)[0], get_Q_values(session, exp_buffer.sample_buffer(4)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T06:41:36.503987Z",
     "start_time": "2018-01-14T06:41:36.500484Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_buffer.sample_buffer(4)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:49:12.837622Z",
     "start_time": "2018-01-07T17:49:12.753540Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21902370e80>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAD8CAYAAADkM2ZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21902255198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state.screen_buffer[::2, ::2, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
