{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:02:11.568498Z",
     "start_time": "2018-01-23T06:02:10.292755Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import scipy.misc\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "from IPython.display import HTML\n",
    "\n",
    "#Import the vizdoom package as \"vd\" since it can't be installed normally on Windows\n",
    "\n",
    "vd_location = 'C:/Anaconda3/envs/doom/Lib/site-packages/vizdoom/vizdoom.pyd'\n",
    "vizdoom = importlib.util.spec_from_file_location('vizdoom',\n",
    "                                                 vd_location)\n",
    "vd = importlib.util.module_from_spec(vizdoom)\n",
    "vizdoom.loader.exec_module(vd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:02:11.711136Z",
     "start_time": "2018-01-23T06:02:11.569500Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Specify the game scenario and the screen format/resolution\n",
    "\n",
    "game = vd.DoomGame()\n",
    "game.set_screen_format(vd.ScreenFormat.BGR24)\n",
    "game.set_depth_buffer_enabled(True)\n",
    "game.set_screen_resolution(vd.ScreenResolution.RES_160X120)\n",
    "game.load_config('deadly_corridor.cfg')\n",
    "\n",
    "down_sample_ratio = 0.5\n",
    "width = int(game.get_screen_width()*down_sample_ratio)\n",
    "height = int(game.get_screen_height()*down_sample_ratio)\n",
    "channels = game.get_screen_channels() + 1\n",
    "\n",
    "#Specify the available actions in the scenario\n",
    "\n",
    "available_actions = game.get_available_buttons()\n",
    "actions = [list(ohe) for ohe in list(np.identity(len(available_actions)))]\n",
    "num_actions = len(available_actions)\n",
    "\n",
    "#Specify the Q-network learning parameters\n",
    "\n",
    "frame_delay = 12\n",
    "buffer_size = 50000\n",
    "epochs = 200\n",
    "steps_per_epoch = 2000\n",
    "learning_rate = 0.001\n",
    "start_epsilon = 1.0\n",
    "end_epsilon = 0.1\n",
    "batch_size = 100\n",
    "load_model = False\n",
    "save_model = True\n",
    "model_dir = './checkpoints/deadly_corridor.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:02:12.029443Z",
     "start_time": "2018-01-23T06:02:11.712137Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Create a buffer object that holds a set of training experiences (state-action-reward tuples)\n",
    "\n",
    "class Buffer():\n",
    "    def __init__(self, size=1000):\n",
    "        self.buffer = list()\n",
    "        self.length = len(self.buffer)\n",
    "        self.size = size\n",
    "        \n",
    "#Add a new experience to the buffer (remove the oldest experience if the buffer is already full)\n",
    "        \n",
    "    def add_experience(self, experience):\n",
    "        if self.length + 1 >= self.size:\n",
    "            self.buffer[0:(self.length + 1) - self.size] = []\n",
    "        \n",
    "        self.buffer.append(experience)\n",
    "        self.length = len(self.buffer)\n",
    "            \n",
    "#Return a batch of experience arrays randomly sampled from the buffer\n",
    "            \n",
    "    def sample_buffer(self, sample_size):\n",
    "        sample = np.random.randint(self.length, size=sample_size)\n",
    "        s1 = np.concatenate([self.buffer[idx][0] for idx in sample], axis=0)\n",
    "        a = np.array([self.buffer[idx][1] for idx in sample])\n",
    "        r = np.array([self.buffer[idx][2] for idx in sample])\n",
    "        s2 = np.concatenate([self.buffer[idx][3] for idx in sample], axis=0)\n",
    "        terminal = np.array([self.buffer[idx][4] for idx in sample], dtype=np.int32)\n",
    "        \n",
    "        return s1, a, r, s2, terminal\n",
    "\n",
    "#Downsample and normalize an image array representing the game state at a given time stamp\n",
    "\n",
    "def preprocess(image, down_sample_ratio=1):\n",
    "    if down_sample_ratio != 1:\n",
    "        image = scipy.misc.imresize(image, down_sample_ratio)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "#Test the agent using a currently training or previously trained model\n",
    "\n",
    "def test_agent(model, num_episodes, load_model, training=True, session=None, model_dir=None):\n",
    "    if load_model == True:\n",
    "        sess = tf.Session()\n",
    "        print('Loading model from', model_dir)\n",
    "        tf.train.Saver().restore(sess, model_dir)\n",
    "        \n",
    "#Require an existing session if a pretrained model isn't provided\n",
    "        \n",
    "    elif load_model == False:\n",
    "        sess = session\n",
    "\n",
    "    game.set_sound_enabled(True)\n",
    "    episode_rewards = list()\n",
    "    \n",
    "#Avoid reinitializing the game if this was already done by the training process\n",
    "    \n",
    "    if training == False:\n",
    "        game.init()\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        game.new_episode()\n",
    "    \n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state()\n",
    "            buffer = np.concatenate((state.screen_buffer,\n",
    "                                     np.expand_dims(state.depth_buffer,\n",
    "                                                    axis=2)),\n",
    "                                    axis=2)\n",
    "            state1 = preprocess(buffer, down_sample_ratio)\n",
    "            action = model.choose_action(sess, state1)[0]\n",
    "            reward = game.make_action(actions[action])\n",
    "            \n",
    "#Add a delay between each time step so that the episodes occur at normal speed\n",
    "\n",
    "            time.sleep(0.02)\n",
    "        \n",
    "        episode_rewards.append(game.get_total_reward())\n",
    "        print('Test Episode {} Reward: {}'.format(i + 1, game.get_total_reward()))\n",
    "        time.sleep(1)\n",
    "    \n",
    "#Avoid ending the game so that the training process can continue\n",
    "    \n",
    "    if training == False:\n",
    "        game.close()\n",
    "    \n",
    "    return np.mean(episode_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T06:02:12.310214Z",
     "start_time": "2018-01-23T06:02:12.030445Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Create a Q-network to estimate values and choose actions for a given state\n",
    "\n",
    "class Q_network():\n",
    "    def __init__(self, network_name, height, width, channels, learning_rate=0.001):\n",
    "        self.s_t = tf.placeholder(tf.float32,\n",
    "                                  shape=[None, height, width, channels],\n",
    "                                  name=network_name + '_state'\n",
    "                                 )\n",
    "        self.a_t = tf.placeholder(tf.int32,\n",
    "                                  shape=[None],\n",
    "                                  name=network_name + '_action'\n",
    "                                 )\n",
    "        self.Q_target = tf.placeholder(tf.float32,\n",
    "                                       shape=[None, num_actions],\n",
    "                                       name=network_name + '_Q_target'\n",
    "                                      )\n",
    "\n",
    "        self.input_layer = tf.reshape(self.s_t,\n",
    "                                      [-1, height, width, channels],\n",
    "                                      name=network_name + '_input_layer'\n",
    "                                     )\n",
    "        self.conv1 = tf.layers.conv2d(inputs=self.input_layer,\n",
    "                                      filters=32,\n",
    "                                      kernel_size=[8, 8],\n",
    "                                      strides=[4, 4],\n",
    "                                      padding='valid',\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      name=network_name + '_conv1_layer'\n",
    "                                     )\n",
    "        self.conv2 = tf.layers.conv2d(inputs=self.conv1,\n",
    "                                      filters=64,\n",
    "                                      kernel_size=[4, 4],\n",
    "                                      strides=[2, 2],\n",
    "                                      padding='valid',\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      name=network_name + '_conv2_layer'\n",
    "                                     )\n",
    "        self.flatten = tf.reshape(self.conv2,\n",
    "                                  [-1, 6*8*64],\n",
    "                                  name=network_name + '_flatten'\n",
    "                                 )\n",
    "        self.dense = tf.layers.dense(inputs=self.flatten,\n",
    "                                      units=512,\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      name=network_name + '_dense1_layer'\n",
    "                                    )\n",
    "        self.Q_values = tf.layers.dense(inputs=self.dense,\n",
    "                                        units=len(actions),\n",
    "                                        activation=None,\n",
    "                                        name=network_name + '_output_layer'\n",
    "                                       )        \n",
    "    \n",
    "        self.best_action = tf.argmax(self.Q_values, 1)\n",
    "        self.loss = tf.losses.mean_squared_error(self.Q_values,\n",
    "                                                 self.Q_target)\n",
    "        self.adam = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                           name=network_name + '_adam'\n",
    "                                          )\n",
    "        self.train = self.adam.minimize(self.loss)\n",
    "\n",
    "    def calculate_loss(self, session, s, q):\n",
    "        L, _ = session.run([self.loss, self.train],\n",
    "                           feed_dict={self.s_t: s,\n",
    "                                      self.Q_target: q})\n",
    "    \n",
    "        return L\n",
    "\n",
    "#Return the array of Q-values and the best action associated with a given state\n",
    "\n",
    "    def get_Q_values(self, session, s):\n",
    "        Q = session.run(self.Q_values,\n",
    "                        feed_dict={self.s_t: s})\n",
    "\n",
    "        return Q\n",
    "    \n",
    "    def choose_action(self, session, s):\n",
    "        a = session.run(self.best_action,\n",
    "                        feed_dict={self.s_t: s})\n",
    "    \n",
    "        return a\n",
    "    \n",
    "#Create a list of variable update operations\n",
    "\n",
    "def update_graph(variables):\n",
    "    update_ops = list()\n",
    "    \n",
    "#Assign weight values from the network created first to the one created second\n",
    "    \n",
    "    for idx, variable in enumerate(variables[:len(variables)//2]):\n",
    "        op = variable.assign(variables[idx + len(variables)//2].value())\n",
    "        update_ops.append(op)\n",
    "    \n",
    "    return update_ops\n",
    "\n",
    "#Update the target network parameters to match those of the online network\n",
    "\n",
    "def update_target(ops, session):\n",
    "    for op in update_ops:\n",
    "        session.run(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T13:07:16.702482Z",
     "start_time": "2018-01-23T06:02:12.311216Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:13<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Mean Reward: 131.20637590026857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:26<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Mean Reward: 133.057186378479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:30<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Mean Reward: 131.8914068222046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:07<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Mean Reward: 131.41910042572022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:11<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Mean Reward: 132.31385022735597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:10<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Mean Reward: 130.56549856567383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:20<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Mean Reward: 131.11374017333983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:24<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Mean Reward: 131.60551104736328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:23<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Mean Reward: 131.69972844696045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:18<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Mean Reward: 129.60476893615723\n",
      "Epoch 10 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 10 test:\n",
      "Test Episode 1 Reward: 264.51609802246094\n",
      "Test Episode 2 Reward: 100.95640563964844\n",
      "Test Episode 3 Reward: 464.0071716308594\n",
      "Test Episode 4 Reward: 514.6394958496094\n",
      "Test Episode 5 Reward: 260.4552307128906\n",
      "Test Episode 6 Reward: 264.51609802246094\n",
      "Test Episode 7 Reward: 264.51609802246094\n",
      "Test Episode 8 Reward: 264.51609802246094\n",
      "Test Episode 9 Reward: 264.51609802246094\n",
      "Test Episode 10 Reward: 224.53262329101562\n",
      "Average Test Reward: 288.717141724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:11<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Mean Reward: 130.3230729598999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:17<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Mean Reward: 133.49271157073974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:13<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Mean Reward: 130.2524232788086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:14<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Mean Reward: 131.63729677581787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:13<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Mean Reward: 129.50482849884034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:14<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Mean Reward: 131.23255855560302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:15<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Mean Reward: 131.24252757263184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:14<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Mean Reward: 130.60085340118408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:09<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Mean Reward: 130.82890988159178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:05<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Mean Reward: 131.32710369873047\n",
      "Epoch 20 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 20 test:\n",
      "Test Episode 1 Reward: 269.7161560058594\n",
      "Test Episode 2 Reward: 269.7161560058594\n",
      "Test Episode 3 Reward: 437.1587219238281\n",
      "Test Episode 4 Reward: 269.7161560058594\n",
      "Test Episode 5 Reward: 269.7161560058594\n",
      "Test Episode 6 Reward: 280.31324768066406\n",
      "Test Episode 7 Reward: 269.7161560058594\n",
      "Test Episode 8 Reward: 655.4543151855469\n",
      "Test Episode 9 Reward: 224.3813934326172\n",
      "Test Episode 10 Reward: 284.05975341796875\n",
      "Average Test Reward: 322.994821167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:03<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Mean Reward: 130.20504064178468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:56<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Mean Reward: 130.0461135635376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:45<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Mean Reward: 133.7899767074585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:42<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Mean Reward: 132.03242538452147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Mean Reward: 131.33547695159913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:45<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Mean Reward: 131.77674252319335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:43<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Mean Reward: 130.76213765716554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:26<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Mean Reward: 130.21892264556885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:19<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Mean Reward: 133.64876728057862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:16<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Mean Reward: 132.25570106506348\n",
      "Epoch 30 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 30 test:\n",
      "Test Episode 1 Reward: 411.390869140625\n",
      "Test Episode 2 Reward: 270.09959411621094\n",
      "Test Episode 3 Reward: 270.09959411621094\n",
      "Test Episode 4 Reward: 567.1274719238281\n",
      "Test Episode 5 Reward: 321.15367126464844\n",
      "Test Episode 6 Reward: 270.09959411621094\n",
      "Test Episode 7 Reward: 270.09959411621094\n",
      "Test Episode 8 Reward: 251.95318603515625\n",
      "Test Episode 9 Reward: 270.09959411621094\n",
      "Test Episode 10 Reward: 230.5533905029297\n",
      "Average Test Reward: 313.267655945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:13<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Mean Reward: 131.4243786239624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:10<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Mean Reward: 132.0598896408081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:06<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Mean Reward: 129.87737755584718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:10<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Mean Reward: 131.23563849639893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:01<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Mean Reward: 131.16537063598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Mean Reward: 132.718643699646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Mean Reward: 130.7267359085083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Mean Reward: 132.75741297912597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:58<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Mean Reward: 131.84676221466066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:00<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Mean Reward: 130.63669516754152\n",
      "Epoch 40 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 40 test:\n",
      "Test Episode 1 Reward: 422.90850830078125\n",
      "Test Episode 2 Reward: 291.3838195800781\n",
      "Test Episode 3 Reward: 275.18701171875\n",
      "Test Episode 4 Reward: 297.46827697753906\n",
      "Test Episode 5 Reward: 275.18701171875\n",
      "Test Episode 6 Reward: 275.18701171875\n",
      "Test Episode 7 Reward: 470.4149932861328\n",
      "Test Episode 8 Reward: 275.18701171875\n",
      "Test Episode 9 Reward: 559.7353210449219\n",
      "Test Episode 10 Reward: 565.1266326904297\n",
      "Average Test Reward: 370.778559875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:13<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Mean Reward: 131.70997634887695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:58<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Mean Reward: 130.03732364654542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Mean Reward: 130.1307624130249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Mean Reward: 132.44481954193114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Mean Reward: 130.8378092880249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:58<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Mean Reward: 132.3126088027954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Mean Reward: 132.09410712432862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:02<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Mean Reward: 130.0795542449951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Mean Reward: 131.2145549697876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Mean Reward: 132.22678513336183\n",
      "Epoch 50 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 50 test:\n",
      "Test Episode 1 Reward: 192.49594116210938\n",
      "Test Episode 2 Reward: 255.6304931640625\n",
      "Test Episode 3 Reward: 280.0997619628906\n",
      "Test Episode 4 Reward: 456.85589599609375\n",
      "Test Episode 5 Reward: 294.95274353027344\n",
      "Test Episode 6 Reward: 280.24900817871094\n",
      "Test Episode 7 Reward: 271.63816833496094\n",
      "Test Episode 8 Reward: 294.95274353027344\n",
      "Test Episode 9 Reward: 294.95274353027344\n",
      "Test Episode 10 Reward: 901.4931488037109\n",
      "Average Test Reward: 352.332064819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Mean Reward: 131.6921770401001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Mean Reward: 131.6787165145874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Mean Reward: 130.65775563049317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:58<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Mean Reward: 130.01766913604737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:08<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Mean Reward: 134.26259873199461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Mean Reward: 129.5280708694458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Mean Reward: 131.0260886077881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Mean Reward: 130.05763639831542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Mean Reward: 131.1292155532837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Mean Reward: 132.25443745422362\n",
      "Epoch 60 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 60 test:\n",
      "Test Episode 1 Reward: 294.95274353027344\n",
      "Test Episode 2 Reward: 294.95274353027344\n",
      "Test Episode 3 Reward: 247.9599609375\n",
      "Test Episode 4 Reward: 294.95274353027344\n",
      "Test Episode 5 Reward: 294.95274353027344\n",
      "Test Episode 6 Reward: 294.95274353027344\n",
      "Test Episode 7 Reward: 286.61024475097656\n",
      "Test Episode 8 Reward: 294.95274353027344\n",
      "Test Episode 9 Reward: 294.95274353027344\n",
      "Test Episode 10 Reward: 352.09478759765625\n",
      "Average Test Reward: 295.1334198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Mean Reward: 163.5645233001709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Mean Reward: 165.59354425811767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Mean Reward: 164.50876809692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Mean Reward: 167.42004314422607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Mean Reward: 169.02717230987548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Mean Reward: 172.75494039916993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Mean Reward: 171.9838461151123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Mean Reward: 172.30646137237548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Mean Reward: 178.61751589202882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Mean Reward: 177.84332455444337\n",
      "Epoch 70 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 70 test:\n",
      "Test Episode 1 Reward: 294.95274353027344\n",
      "Test Episode 2 Reward: 275.9210662841797\n",
      "Test Episode 3 Reward: 294.95274353027344\n",
      "Test Episode 4 Reward: 294.95274353027344\n",
      "Test Episode 5 Reward: 294.95274353027344\n",
      "Test Episode 6 Reward: 294.95274353027344\n",
      "Test Episode 7 Reward: 294.95274353027344\n",
      "Test Episode 8 Reward: 315.0540771484375\n",
      "Test Episode 9 Reward: 508.6257019042969\n",
      "Test Episode 10 Reward: 294.95274353027344\n",
      "Average Test Reward: 316.427005005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Mean Reward: 179.52298892211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Mean Reward: 181.38222532653808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Mean Reward: 185.42917849731447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Mean Reward: 184.52146026611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Mean Reward: 186.7009514846802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Mean Reward: 187.13776959228517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Mean Reward: 190.43890279388427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Mean Reward: 187.11586281585693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Mean Reward: 191.30172992706298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Mean Reward: 195.6367014389038\n",
      "Epoch 80 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 80 test:\n",
      "Test Episode 1 Reward: 565.8706665039062\n",
      "Test Episode 2 Reward: 283.61073303222656\n",
      "Test Episode 3 Reward: 283.61073303222656\n",
      "Test Episode 4 Reward: 283.61073303222656\n",
      "Test Episode 5 Reward: 536.4062194824219\n",
      "Test Episode 6 Reward: 283.61073303222656\n",
      "Test Episode 7 Reward: 241.91311645507812\n",
      "Test Episode 8 Reward: 277.8139953613281\n",
      "Test Episode 9 Reward: 283.61073303222656\n",
      "Test Episode 10 Reward: 283.61073303222656\n",
      "Average Test Reward: 332.3668396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:02<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Mean Reward: 195.814486618042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Mean Reward: 199.6089612197876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Mean Reward: 201.7995360107422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Mean Reward: 205.32664278411866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Mean Reward: 207.56846866607665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Mean Reward: 203.67402701568602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:02<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Mean Reward: 208.0365939025879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Mean Reward: 207.96239978790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Mean Reward: 211.1049502029419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Mean Reward: 212.1195323562622\n",
      "Epoch 90 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 90 test:\n",
      "Test Episode 1 Reward: 283.2568817138672\n",
      "Test Episode 2 Reward: 464.0641784667969\n",
      "Test Episode 3 Reward: 283.2568817138672\n",
      "Test Episode 4 Reward: 283.2568817138672\n",
      "Test Episode 5 Reward: 283.2568817138672\n",
      "Test Episode 6 Reward: 283.2568817138672\n",
      "Test Episode 7 Reward: 680.38916015625\n",
      "Test Episode 8 Reward: 245.0606689453125\n",
      "Test Episode 9 Reward: 283.2568817138672\n",
      "Test Episode 10 Reward: 283.2568817138672\n",
      "Average Test Reward: 337.231217957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Mean Reward: 219.76105111694335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Mean Reward: 216.56636153411864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Mean Reward: 221.024774848938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:01<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Mean Reward: 220.78270793151856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Mean Reward: 224.40804636383058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:45<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Mean Reward: 222.77379957580567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:47<00:00, 18.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Mean Reward: 229.14928831481933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Mean Reward: 225.41577755737305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Mean Reward: 232.52456301116942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Mean Reward: 232.36669234466552\n",
      "Epoch 100 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 100 test:\n",
      "Test Episode 1 Reward: 554.3011627197266\n",
      "Test Episode 2 Reward: 408.5043182373047\n",
      "Test Episode 3 Reward: 568.8609161376953\n",
      "Test Episode 4 Reward: 408.5043182373047\n",
      "Test Episode 5 Reward: 509.5507354736328\n",
      "Test Episode 6 Reward: 279.9243621826172\n",
      "Test Episode 7 Reward: 554.3011627197266\n",
      "Test Episode 8 Reward: 408.5043182373047\n",
      "Test Episode 9 Reward: 554.3011627197266\n",
      "Test Episode 10 Reward: 449.739501953125\n",
      "Average Test Reward: 469.649195862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Mean Reward: 236.59270111846925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Mean Reward: 238.63062355804442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 Mean Reward: 238.01099868011474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 Mean Reward: 241.18932048797606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Mean Reward: 244.98950969696045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 Mean Reward: 242.49417646026612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 Mean Reward: 245.05974826049805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Mean Reward: 248.84493265533447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 Mean Reward: 244.11198652648926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:07<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 Mean Reward: 253.526777053833\n",
      "Epoch 110 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 110 test:\n",
      "Test Episode 1 Reward: 649.2366333007812\n",
      "Test Episode 2 Reward: 274.50537109375\n",
      "Test Episode 3 Reward: 329.61016845703125\n",
      "Test Episode 4 Reward: 274.50537109375\n",
      "Test Episode 5 Reward: 547.9924774169922\n",
      "Test Episode 6 Reward: 292.44642639160156\n",
      "Test Episode 7 Reward: 327.7057189941406\n",
      "Test Episode 8 Reward: 461.6768035888672\n",
      "Test Episode 9 Reward: 274.50537109375\n",
      "Test Episode 10 Reward: 262.58863830566406\n",
      "Average Test Reward: 369.477297974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:58<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 Mean Reward: 252.00183375549315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 Mean Reward: 258.05440036773683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:01<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 Mean Reward: 259.9622224884033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:00<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Mean Reward: 265.62524797821044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 Mean Reward: 269.71281997680666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 Mean Reward: 268.58051694488523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:15<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 Mean Reward: 271.4864945983887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 Mean Reward: 277.0050301361084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:02<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Mean Reward: 278.390573928833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Mean Reward: 278.4549535903931\n",
      "Epoch 120 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 120 test:\n",
      "Test Episode 1 Reward: 589.8568420410156\n",
      "Test Episode 2 Reward: 433.3393096923828\n",
      "Test Episode 3 Reward: 220.64112854003906\n",
      "Test Episode 4 Reward: 433.3393096923828\n",
      "Test Episode 5 Reward: 499.2216339111328\n",
      "Test Episode 6 Reward: 279.7518615722656\n",
      "Test Episode 7 Reward: 565.3341674804688\n",
      "Test Episode 8 Reward: 433.3393096923828\n",
      "Test Episode 9 Reward: 519.3215942382812\n",
      "Test Episode 10 Reward: 433.3393096923828\n",
      "Average Test Reward: 440.748446655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 Mean Reward: 272.1907244262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 Mean Reward: 271.8118034286499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Mean Reward: 272.43620394134524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 Mean Reward: 274.28623601531984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:08<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 Mean Reward: 280.51985722351077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 Mean Reward: 282.98553855895995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Mean Reward: 279.73729192352295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 Mean Reward: 277.8429881515503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 Mean Reward: 286.8635755233765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 Mean Reward: 290.7985429840088\n",
      "Epoch 130 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 130 test:\n",
      "Test Episode 1 Reward: 566.2972106933594\n",
      "Test Episode 2 Reward: 264.96099853515625\n",
      "Test Episode 3 Reward: 389.8818817138672\n",
      "Test Episode 4 Reward: 278.9537658691406\n",
      "Test Episode 5 Reward: 278.9537658691406\n",
      "Test Episode 6 Reward: 278.9537658691406\n",
      "Test Episode 7 Reward: 278.9537658691406\n",
      "Test Episode 8 Reward: 549.0405426025391\n",
      "Test Episode 9 Reward: 278.9537658691406\n",
      "Test Episode 10 Reward: 300.62586975097656\n",
      "Average Test Reward: 346.557533264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Mean Reward: 313.04249699401856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:02<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Mean Reward: 312.1344484863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 Mean Reward: 308.71012237548825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Mean Reward: 321.5422250595093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 Mean Reward: 318.91040743255616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 Mean Reward: 326.61759368133545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 Mean Reward: 322.5748907623291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Mean Reward: 320.32940660858156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 Mean Reward: 321.9869648513794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 Mean Reward: 328.44694805908205\n",
      "Epoch 140 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 140 test:\n",
      "Test Episode 1 Reward: 442.9654083251953\n",
      "Test Episode 2 Reward: 442.9654083251953\n",
      "Test Episode 3 Reward: 442.9654083251953\n",
      "Test Episode 4 Reward: 227.25901794433594\n",
      "Test Episode 5 Reward: 442.9654083251953\n",
      "Test Episode 6 Reward: 442.9654083251953\n",
      "Test Episode 7 Reward: 223.1187744140625\n",
      "Test Episode 8 Reward: 442.9654083251953\n",
      "Test Episode 9 Reward: 268.7892761230469\n",
      "Test Episode 10 Reward: 442.9654083251953\n",
      "Average Test Reward: 381.992492676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 Mean Reward: 340.2140690612793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 Mean Reward: 335.42985098266604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 Mean Reward: 343.08025065612793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Mean Reward: 338.7953411712646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 Mean Reward: 347.06300775909426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 Mean Reward: 341.4664251556396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:07<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 Mean Reward: 344.67511011505127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Mean Reward: 352.0231597595215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 Mean Reward: 345.6266469497681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 Mean Reward: 355.83319284057615\n",
      "Epoch 150 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 150 test:\n",
      "Test Episode 1 Reward: 267.1122741699219\n",
      "Test Episode 2 Reward: 267.1122741699219\n",
      "Test Episode 3 Reward: 267.1122741699219\n",
      "Test Episode 4 Reward: 267.1122741699219\n",
      "Test Episode 5 Reward: 267.1122741699219\n",
      "Test Episode 6 Reward: 229.29595947265625\n",
      "Test Episode 7 Reward: 196.74769592285156\n",
      "Test Episode 8 Reward: 267.1122741699219\n",
      "Test Episode 9 Reward: 267.1122741699219\n",
      "Test Episode 10 Reward: 603.4388122558594\n",
      "Average Test Reward: 289.926838684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 Mean Reward: 361.89661605072024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 Mean Reward: 364.56293074798583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 Mean Reward: 369.88603582000735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 Mean Reward: 369.60674907684324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 Mean Reward: 374.1327777709961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:11<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 Mean Reward: 383.00821771240237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157 Mean Reward: 381.9009682006836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 Mean Reward: 390.7051066055298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 Mean Reward: 395.9182024230957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 Mean Reward: 402.7312011489868\n",
      "Epoch 160 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 160 test:\n",
      "Test Episode 1 Reward: 409.42735290527344\n",
      "Test Episode 2 Reward: 409.42735290527344\n",
      "Test Episode 3 Reward: 409.42735290527344\n",
      "Test Episode 4 Reward: 409.42735290527344\n",
      "Test Episode 5 Reward: 493.9055938720703\n",
      "Test Episode 6 Reward: 468.6914825439453\n",
      "Test Episode 7 Reward: 182.6830291748047\n",
      "Test Episode 8 Reward: 409.42735290527344\n",
      "Test Episode 9 Reward: 260.16900634765625\n",
      "Test Episode 10 Reward: 409.42735290527344\n",
      "Average Test Reward: 386.201322937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:49<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161 Mean Reward: 406.9395208816528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 Mean Reward: 411.8677098617554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163 Mean Reward: 394.21250789642335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:03<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 Mean Reward: 403.53686395263674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:48<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 Mean Reward: 401.45045484924316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 Mean Reward: 402.68201430511476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 Mean Reward: 413.8208252182007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 Mean Reward: 417.8688429336548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 Mean Reward: 425.13627980804443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 Mean Reward: 431.07256774139404\n",
      "Epoch 170 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 170 test:\n",
      "Test Episode 1 Reward: 280.17100524902344\n",
      "Test Episode 2 Reward: 547.0067138671875\n",
      "Test Episode 3 Reward: 280.17100524902344\n",
      "Test Episode 4 Reward: 250.56629943847656\n",
      "Test Episode 5 Reward: 280.17100524902344\n",
      "Test Episode 6 Reward: 297.5193176269531\n",
      "Test Episode 7 Reward: 280.17100524902344\n",
      "Test Episode 8 Reward: 700.7275543212891\n",
      "Test Episode 9 Reward: 280.17100524902344\n",
      "Test Episode 10 Reward: 304.5230407714844\n",
      "Average Test Reward: 350.119795227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171 Mean Reward: 461.59445695495606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:05<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 Mean Reward: 465.9225468826294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173 Mean Reward: 476.3599847946167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 Mean Reward: 482.754192276001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 Mean Reward: 487.606626335144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:56<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 Mean Reward: 491.13189595794677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:52<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177 Mean Reward: 486.65547205352783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:09<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178 Mean Reward: 491.3819272994995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 Mean Reward: 524.4509245147705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:01<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 Mean Reward: 522.7353393707275\n",
      "Epoch 180 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 180 test:\n",
      "Test Episode 1 Reward: 110.2789306640625\n",
      "Test Episode 2 Reward: 229.00808715820312\n",
      "Test Episode 3 Reward: 224.3655242919922\n",
      "Test Episode 4 Reward: 224.3655242919922\n",
      "Test Episode 5 Reward: 224.3655242919922\n",
      "Test Episode 6 Reward: 202.8043670654297\n",
      "Test Episode 7 Reward: 224.3655242919922\n",
      "Test Episode 8 Reward: 224.3655242919922\n",
      "Test Episode 9 Reward: 224.3655242919922\n",
      "Test Episode 10 Reward: 224.3655242919922\n",
      "Average Test Reward: 211.265005493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181 Mean Reward: 526.3715040588379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 Mean Reward: 528.9832680892945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183 Mean Reward: 533.1092561340332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 Mean Reward: 535.2428143081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 Mean Reward: 532.3555188522339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:07<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 Mean Reward: 531.5433667449951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187 Mean Reward: 529.0116111602783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188 Mean Reward: 529.1577212524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:51<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 Mean Reward: 533.4689818649292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 Mean Reward: 536.9188267822266\n",
      "Epoch 190 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 190 test:\n",
      "Test Episode 1 Reward: 373.61695861816406\n",
      "Test Episode 2 Reward: 535.854736328125\n",
      "Test Episode 3 Reward: 506.0320129394531\n",
      "Test Episode 4 Reward: 393.14263916015625\n",
      "Test Episode 5 Reward: 275.61334228515625\n",
      "Test Episode 6 Reward: 373.61695861816406\n",
      "Test Episode 7 Reward: 373.61695861816406\n",
      "Test Episode 8 Reward: 373.61695861816406\n",
      "Test Episode 9 Reward: 373.61695861816406\n",
      "Test Episode 10 Reward: 241.77830505371094\n",
      "Average Test Reward: 382.050582886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:54<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191 Mean Reward: 507.3721851501465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 Mean Reward: 503.6634953765869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:53<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193 Mean Reward: 493.4234599227905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:09<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194 Mean Reward: 491.18895847320556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 Mean Reward: 496.6380216293335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 Mean Reward: 487.02569772338865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:55<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197 Mean Reward: 486.6309999771118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:00<00:00, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 Mean Reward: 492.0435645675659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 Mean Reward: 491.4137775039673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:57<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 Mean Reward: 490.0376734542847\n",
      "Epoch 200 Model saved to ./checkpoints/deadly_corridor.ckpt\n",
      "Epoch 200 test:\n",
      "Test Episode 1 Reward: 139.0738525390625\n",
      "Test Episode 2 Reward: 528.2173156738281\n",
      "Test Episode 3 Reward: 256.66539001464844\n",
      "Test Episode 4 Reward: 255.59927368164062\n",
      "Test Episode 5 Reward: 256.66539001464844\n",
      "Test Episode 6 Reward: 256.66539001464844\n",
      "Test Episode 7 Reward: 256.66539001464844\n",
      "Test Episode 8 Reward: 210.04180908203125\n",
      "Test Episode 9 Reward: 256.66539001464844\n",
      "Test Episode 10 Reward: 256.66539001464844\n",
      "Average Test Reward: 267.292459106\n",
      "[(469.64919586181639, 100), (440.74844665527343, 120), (386.2013229370117, 160), (382.05058288574219, 190), (381.99249267578125, 140), (370.77855987548827, 40), (369.4772979736328, 110), (352.33206481933593, 50), (350.11979522705076, 170), (346.55753326416016, 130), (337.23121795654299, 90), (332.36683959960936, 80), (322.99482116699221, 20), (316.4270050048828, 70), (313.26765594482424, 30), (295.1334197998047, 60), (289.92683868408204, 150), (288.71714172363284, 10), (267.29245910644534, 200), (211.26500549316407, 180)]\n",
      "3192264 time steps experienced during training\n"
     ]
    }
   ],
   "source": [
    "#For each time step, collect the following data:\n",
    "#The current game state\n",
    "#The action that was taken taken\n",
    "#The reward obtained from the chosen action\n",
    "#The next game state (store the first game state if the previous action ends the episode)\n",
    "#A variable indicating whether the episode is over yet\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Instantiate the target network before the online network so that it's updated correctly\n",
    "\n",
    "target_net = Q_network(network_name='target',\n",
    "                       learning_rate=learning_rate,\n",
    "                       height=height,\n",
    "                       width=width,\n",
    "                       channels=channels)\n",
    "DQN = Q_network(network_name='online',\n",
    "                learning_rate=learning_rate,\n",
    "                height=height,\n",
    "                width=width,\n",
    "                channels=channels)\n",
    "\n",
    "exp_buffer = Buffer(size=buffer_size)\n",
    "session = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "weights = tf.trainable_variables()\n",
    "\n",
    "update_ops = update_graph(weights)\n",
    "\n",
    "if load_model == True:\n",
    "    print('Loading model from', model_dir)\n",
    "    tf.train.Saver().restore(session, model_dir)\n",
    "    \n",
    "elif load_model == False:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "game.set_sound_enabled(False)\n",
    "game.init()\n",
    "\n",
    "gamma = 0\n",
    "t = 0\n",
    "epoch_rank = list()\n",
    "\n",
    "#Accumulate experiences in the buffer using an epsilon-greedy strategy with three training phases\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_rewards = list()\n",
    "    \n",
    "#Increase the discount factor at each epoch until it reaches approximately 0.99\n",
    "    \n",
    "    gamma = 1-.9775*(1-gamma)\n",
    "    \n",
    "    for step in trange(steps_per_epoch, leave=True):\n",
    "        experience = list()\n",
    "        game.new_episode()\n",
    "        \n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state()\n",
    "            state1 = preprocess(np.concatenate((state.screen_buffer,\n",
    "                                                np.expand_dims(state.depth_buffer, axis=2)),\n",
    "                                                axis=2),\n",
    "                                               down_sample_ratio)\n",
    "            \n",
    "#Explore the environment by choosing random actions with 100% probability for the first phase of training\n",
    "\n",
    "            if epoch < 0.3*epochs:\n",
    "                action = np.random.randint(num_actions)\n",
    "            \n",
    "#Increase the probability of greedily choosing an action by a constant amount at each epoch in the second phase\n",
    "            \n",
    "            elif epoch < 0.9*epochs:\n",
    "                epsilon = start_epsilon - (epoch + 1 - 0.2*epochs)*(start_epsilon-end_epsilon)/(0.7*epochs)\n",
    "            \n",
    "                if np.random.uniform(0, 1) <= epsilon:\n",
    "                    action = np.random.randint(num_actions)\n",
    "                \n",
    "                else:\n",
    "                    action = DQN.choose_action(session, state1)[0]\n",
    "\n",
    "#Select a random action with 10% probability in the final phase of training\n",
    "                \n",
    "            else:\n",
    "                if np.random.uniform(0, 1) <= end_epsilon:\n",
    "                    action = np.random.randint(num_actions)\n",
    "                    \n",
    "                else:\n",
    "                    action = DQN.choose_action(session, state1)[0]\n",
    "\n",
    "            reward = game.make_action(actions[action], frame_delay)\n",
    "            done = game.is_episode_finished()\n",
    "            \n",
    "            if done == False:\n",
    "                state = game.get_state()\n",
    "                state2 = preprocess(np.concatenate((state.screen_buffer,\n",
    "                                                    np.expand_dims(state.depth_buffer, axis=2)),\n",
    "                                                    axis=2),\n",
    "                                                    down_sample_ratio)\n",
    "        \n",
    "            elif done == True:\n",
    "                state2 = state1\n",
    "        \n",
    "#Add the experience obtained from each time step to the buffer\n",
    "\n",
    "            t += 1\n",
    "            exp_buffer.add_experience((state1, action, reward, state2, done))\n",
    "        \n",
    "#Sample a minibatch from the buffer if there are enough experiences in the buffer\n",
    "\n",
    "        if exp_buffer.length > batch_size:\n",
    "            s1, a, r, s2, terminal = exp_buffer.sample_buffer(batch_size)\n",
    "            \n",
    "#Get the target values from the target Q-network\n",
    "            \n",
    "            target_Q = np.max(target_net.get_Q_values(session, s2), axis=1)\n",
    "            \n",
    "#Train the online Q-network by using a minibatch to update the action-value function\n",
    "            \n",
    "            Q2 = DQN.get_Q_values(session, s1)\n",
    "            Q2[np.arange(batch_size), a] = r + gamma*(1 - terminal)*target_Q\n",
    "            DQN.calculate_loss(session, s1, Q2)\n",
    "            \n",
    "        epoch_rewards.append(game.get_total_reward())\n",
    "    \n",
    "    print('Epoch {} Mean Reward: {}'.format(epoch + 1, np.mean(epoch_rewards)))\n",
    "    \n",
    "#Save the model, update the target network, and test the agent for 10 episodes every 10 epochs\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 and epoch > 0:\n",
    "        if save_model == True:\n",
    "            checkpoint = model_dir + '-' + str(epoch + 1)\n",
    "            print('Epoch {} Model saved to {}'.format(epoch + 1, model_dir))\n",
    "            saver.save(session, model_dir, global_step=epoch + 1)\n",
    "            \n",
    "        update_target(update_ops, session)\n",
    "\n",
    "        print('Epoch {} test:'.format(epoch + 1))\n",
    "        test_reward = test_agent(DQN, num_episodes=10,\n",
    "                                 training=True,\n",
    "                                 load_model=False,\n",
    "                                 session=session,\n",
    "                                 model_dir=model_dir)\n",
    "        print('Average Test Reward:', test_reward)\n",
    "        epoch_rank.append((test_reward, epoch + 1))\n",
    "        \n",
    "#Return a sorted list of epoch checkpoints based on average test episode reward\n",
    "        \n",
    "print(sorted(epoch_rank, reverse=True))\n",
    "print('{} time steps experienced during training'.format(t))\n",
    "game.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T13:15:00.599789Z",
     "start_time": "2018-01-23T13:14:02.502805Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints\\deadly_corridor.ckpt-200\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\deadly_corridor.ckpt-200\n",
      "Test Episode 1 Reward: 474.33421325683594\n",
      "Test Episode 2 Reward: 265.6115264892578\n",
      "Test Episode 3 Reward: 332.4654846191406\n",
      "Test Episode 4 Reward: 209.7943572998047\n",
      "Test Episode 5 Reward: 332.4654846191406\n",
      "Test Episode 6 Reward: 280.36224365234375\n",
      "Test Episode 7 Reward: 221.31776428222656\n",
      "Test Episode 8 Reward: 90.81770324707031\n",
      "Test Episode 9 Reward: 332.4654846191406\n",
      "Test Episode 10 Reward: 163.6245574951172\n",
      "Test Episode 11 Reward: 332.4654846191406\n",
      "Test Episode 12 Reward: 274.8756103515625\n",
      "Test Episode 13 Reward: 332.4654846191406\n",
      "Test Episode 14 Reward: 483.62811279296875\n",
      "Test Episode 15 Reward: 332.4654846191406\n",
      "Test Episode 16 Reward: 332.4654846191406\n",
      "Test Episode 17 Reward: 164.77279663085938\n",
      "Test Episode 18 Reward: 332.4654846191406\n",
      "Test Episode 19 Reward: 302.7548828125\n",
      "Test Episode 20 Reward: 205.616455078125\n",
      "Average Test Reward: 289.861705017\n"
     ]
    }
   ],
   "source": [
    "#Get a list of checkpoints saved during training\n",
    "\n",
    "ckpts = tf.train.get_checkpoint_state('checkpoints').all_model_checkpoint_paths\n",
    "\n",
    "#Test the trained model from a certain checkpoint by only choosing actions with a greedy strategy\n",
    "\n",
    "test_reward = test_agent(DQN, num_episodes=20, training=False, load_model=True, model_dir=ckpts[-1])\n",
    "print('Average Test Reward:', test_reward)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
